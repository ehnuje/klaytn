package database

import (
	"database/sql"
	"errors"
	"fmt"
	"github.com/go-pg/pg"
	_ "github.com/go-sql-driver/mysql"
	"github.com/jinzhu/gorm"
	_ "github.com/jinzhu/gorm/dialects/postgres"
	"github.com/klaytn/klaytn/common"
	"github.com/klaytn/klaytn/log"
	_ "github.com/mattn/go-sqlite3"
	"strings"
	"time"
)

//type KeyValueModel struct {
//	Id  int    `gorm:"column:id;type:INT AUTO_INCREMENT;PRIMARY_KEY;NOT NULL"`
//	Key []byte `gorm:"column:binkey;type:VARBINARY(100);UNIQUE_INDEX;NOT NULL"`
//	Val []byte `gorm:"column:binval;type:MEDIUMBLOB"`
//}

type KeyValueModel struct {
	Id  int    `gorm:"column:id;type:INT GENERATED BY DEFAULT AS IDENTITY;PRIMARY_KEY;NOT NULL"`
	Key []byte `gorm:"column:binkey;type:bytea;UNIQUE;NOT NULL"`
	Val []byte `gorm:"column:binval;type:bytea"`
}

const mysqlDialect = "mysql"
const sqliteDialect = "sqlite3"
const postgresDialect = "postgres"

type rdb struct {
	db              *gorm.DB
	dialect         string
	sqlDB           *sql.DB
	pgDB            *pg.DB
	sqlPreparedStmt *sql.Stmt
	pgPreparedStmt  *pg.Stmt
	logger          log.Logger
}

func newRelationalDatabase(defaultEndpoint, dialect string) (*rdb, error) {
	var db *gorm.DB
	var sqlDB *sql.DB
	var pgDB *pg.DB
	var err error

	switch dialect {
	case postgresDialect:
		id, password, dbname := "junhee", "junhee", "junhee"
		host := "localhost"
		defaultEndpoint = fmt.Sprintf("host=%s port=5432 user=%s dbname=%s password=%s sslmode=disable", host, id, dbname, password)
		//defaultEndpoint = fmt.Sprintf("host=kes-test-melvin-postgres.cnuopt13avbx.ap-northeast-2.rds.amazonaws.com port=5432 user=%s dbname=%s password=%s sslmode=disable", id, dbname, password)

		db, err = openDatabase(dialect, defaultEndpoint)

		pgDB = pg.Connect(&pg.Options{
			Addr:     fmt.Sprintf("%s:%v", host, 5432),
			User:     id,
			Password: password,
			Database: dbname,
		})

	case mysqlDialect:
		id, password := "root", "root"

		defaultEndpoint = fmt.Sprintf("%s:%s@/test", id, password)
		//defaultEndpoint = fmt.Sprintf("%s:%s@tcp(kes-melvin-test-mysql.cnuopt13avbx.ap-northeast-2.rds.amazonaws.com:3306)/mysql", id, password)
		logger.Info("defaultEndpoint", "ep", defaultEndpoint)
		db, err = openDatabase(dialect, defaultEndpoint)
		setMySQLDatabase(db)

		endpoint2 := defaultEndpoint
		//endpoint2 := fmt.Sprintf("%s:%s@tcp(kes-melvin-test-mysql.cnuopt13avbx.ap-northeast-2.rds.amazonaws.com:3306)/test", id, password)
		db, err = openDatabase(dialect, endpoint2)
		if err := db.Exec("USE test").Error; err != nil {
			return nil, err
		}

		sqlDB, err = sql.Open(dialect, endpoint2)
		if err != nil {
			logger.Error("failed to open database", "err", err)
		}
		_, err = sqlDB.Exec("USE test")
		if err != nil {
			logger.Error("failed to set database", "err", err)
		}

	case sqliteDialect:
		db, err = gorm.Open("sqlite3", ":memory:")

	default:
		return nil, fmt.Errorf("%w - given dialect: %s", notSupportedDialectErr, dialect)
	}

	if err != nil {
		return nil, err
	}

	//db.LogMode(true)

	//logger.Info("")
	//if err := db.Exec("USE test").Error; err != nil {
	//	logger.Error("Failed to use test", "err", err)
	//}

	err = db.AutoMigrate(&KeyValueModel{}).Error
	if err != nil {
		return nil, err
	}

	return &rdb{
		db:      db,
		dialect: dialect,
		sqlDB:   sqlDB,
		pgDB:    pgDB,
		logger:  logger.NewWith("", "")}, nil
}

func openDatabase(dialect, endpoint string) (*gorm.DB, error) {
	var db *gorm.DB
	var err error
	for i := 0; i < 5; i++ {
		db, err = gorm.Open(dialect, endpoint)
		if err == nil {
			return db, nil
		}

		if strings.Contains(err.Error(), "connect: connection refused") {
			logger.Info("sleep for a while and retry connecting to db", "endpoint", endpoint)
			time.Sleep(1 * time.Second)
		} else {
			logger.Error("failed to connect to database", "tried", i+1, "err", err)
		}
	}

	return db, err
}

func setMySQLDatabase(mysql *gorm.DB) error {
	//Drop previous test database if possible.
	//if err := mysql.Exec("DROP DATABASE test").Error; err != nil {
	//	if !strings.Contains(err.Error(), "database doesn't exist") {
	//		logger.Error("Error while dropping the database test", "err", err)
	//	}
	//}
	//// Create new test database.
	if err := mysql.Exec("CREATE DATABASE test").Error; err != nil {
		logger.Error("Error while creating database", "err", err)
	}
	// Use test database
	if err := mysql.Exec("USE test").Error; err != nil {
		return err
	}

	//if err := mysql.Exec("SET profiling = 1").Error; err != nil {
	//	return err
	//}
	return nil
}

const mysqlPutQuery = `
			INSERT /*+ SET_VAR(performance_schema = ON) */ INTO test.key_value_models(binkey, binval)
			VALUES (?, ?) 
			ON DUPLICATE KEY UPDATE binval=values(binval)`

const mysqlBatchQuery = `
			INSERT /*+ SET_VAR(performance_schema = ON) */ INTO test.key_value_models(binkey, binval)
			VALUES %s 
			ON DUPLICATE KEY UPDATE binkey=values(binkey), binval=values(binval)`

const sqlitePutQuery = `
			INSERT INTO key_value_models(binkey, binval)
			VALUES (?, ?)
			ON CONFLICT (binkey)
			DO
			UPDATE SET binval=excluded.binval`

const sqliteBatchQuery = `
			INSERT INTO key_value_models(binkey, binval)
			VALUES %s
			ON CONFLICT (binkey)
			DO
			UPDATE SET binval=excluded.binval`

var notSupportedDialectErr = errors.New("given dialect is not supported")

func (rdb *rdb) Put(key []byte, val []byte) error {
	switch rdb.db.Dialect().GetName() {
	case mysqlDialect:
		return rdb.db.Exec(mysqlPutQuery, key, val).Error
	case sqliteDialect:
		return rdb.db.Exec(sqlitePutQuery, key, val).Error
	case postgresDialect:
		return rdb.db.Exec(sqlitePutQuery, key, val).Error
	default:
		return fmt.Errorf("%w - given dialect: %s", notSupportedDialectErr, rdb.db.Dialect().GetName())
	}
}

func (rdb *rdb) Get(key []byte) ([]byte, error) {
	var result KeyValueModel
	if err := rdb.db.Where(&KeyValueModel{Key: key}).Take(&result).Error; err != nil {
		return nil, err
	}
	return result.Val, nil
}

func (rdb *rdb) Has(key []byte) (bool, error) {
	if val, err := rdb.Get(key); val != nil && err == nil {
		return true, nil
	} else {
		return false, err
	}
}

func (rdb *rdb) Delete(key []byte) error {
	return rdb.db.Delete(&KeyValueModel{Key: key}).Error
}

func (rdb *rdb) Close() {
	if err := rdb.db.Close(); err != nil {
		rdb.logger.Error("error while closing relational database", "err", err)
	} else {
		rdb.logger.Info("successfully closed relational database")
	}
}

func (rdb *rdb) NewBatch() Batch {
	return &rdbBatch{
		db:         rdb.db,
		rdb:        rdb,
		batchItems: []*KeyValueModel{},
		size:       0,
	}
}

func (rdb *rdb) Type() DBType {
	return RelationalDB
}

func (rdb *rdb) Meter(prefix string) {
	// does nothing
}

type rdbBatch struct {
	db         *gorm.DB
	rdb        *rdb
	batchItems []*KeyValueModel
	size       int
}

func (b *rdbBatch) Put(key, val []byte) error {
	//logger.Info("batchItem Put", "key", common.BytesToHash(key).String())
	b.batchItems = append(b.batchItems, &KeyValueModel{Key: key, Val: val})
	b.size += len(val)
	return nil
}

func (b *rdbBatch) pgWrite() error {
	var placeholders []string
	var queryArgs []interface{}

	numItems := 0

	maxBatchSize := 3000
	writeSize := 0

	placeHoldersCount := 1
	for _, item := range b.batchItems {
		numItems++

		placeholders = append(placeholders, fmt.Sprintf("($%v::bytea, $%v::bytea)", placeHoldersCount, placeHoldersCount+1))
		placeHoldersCount += 2
		queryArgs = append(queryArgs, item.Key)
		queryArgs = append(queryArgs, item.Val)
		writeSize += len(item.Val)

		if numItems >= maxBatchSize {
			if b.rdb.pgPreparedStmt == nil {
				concatenatedPlaceholders := strings.Join(placeholders, ",")
				query := fmt.Sprintf(sqliteBatchQuery, concatenatedPlaceholders)

				stmt, err := b.rdb.pgDB.Prepare(query)
				if err != nil {
					logger.Error("Error while prepare query", "err", err)
				}
				b.rdb.pgPreparedStmt = stmt
			}

			batchWriteStart := time.Now()
			_, err := b.rdb.pgPreparedStmt.Exec(queryArgs...)
			if err != nil {
				logger.Error("Error while batch write", "err", err)
				return err
			}

			writeTime := time.Since(batchWriteStart)
			logger.Info("BatchWrite 3000 items", "elapsed", writeTime, "numItems", numItems, "writeSize", writeSize)
			relationalDBBatchWriteMeter.Mark(int64(writeTime / 3000.0))

			placeholders = []string{}
			queryArgs = []interface{}{}
			numItems = 0
			writeSize = 0
		}
	}

	if numItems == 0 {
		return nil
	}

	startRemaining := time.Now()
	defer func() {
		writeRemainingTime := time.Since(startRemaining)
		logger.Info("BatchWrite Remainings", "elapsed", writeRemainingTime, "numItems", numItems)
		relationalDBBatchWriteMeter.Mark(int64(int64(writeRemainingTime) / int64(numItems)))
	}()
	query := fmt.Sprintf(sqliteBatchQuery, strings.Join(placeholders, ","))

	err := b.db.Exec(query, queryArgs...).Error
	if err != nil {
		if strings.Contains(err.Error(), "ON CONFLICT DO UPDATE command cannot affect row a second time") ||
			strings.Contains(err.Error(), "could not determine data type of parameter") {
			for i := len(b.batchItems) - numItems; i < len(b.batchItems); i++ {
				item := b.batchItems[i]
				if err2 := b.rdb.Put(item.Key, item.Val); err2 != nil {
					return err2
				}
			}
			return nil
		}
	}

	if err != nil {
		logger.Error("unexpected error", "err", err)
	}

	return err
}

func (b *rdbBatch) Write() error {
	if b.size == 0 {
		return nil
	}
	start := time.Now()
	defer func() {
		logger.Info("BatchWriteTotal", "elapsed", time.Since(start), "size", b.size, "numItems", len(b.batchItems))
	}()

	if b.rdb.dialect == postgresDialect {
		return b.pgWrite()
	}

	var placeholders []string
	var queryArgs []interface{}

	numItems := 0

	//if err := b.db.Exec("ALTER TABLE test.key_value_models DISABLE KEYS").Error; err != nil {
	//	logger.Error("Error while altering table", "err", err)
	//	return err
	//}
	//
	//defer func() {
	//	if err := b.db.Exec("ALTER TABLE test.key_value_models ENABLE KEYS").Error; err != nil {
	//		logger.Error("Error while altering table", "err", err)
	//	}
	//}()

	maxBatchSize := 750
	writeSize := 0

	for _, item := range b.batchItems {
		//logger.Info("batchItem Write", "key", common.BytesToHash(item.Key).String())
		numItems++

		placeholders = append(placeholders, "(?,?)")
		queryArgs = append(queryArgs, item.Key)
		queryArgs = append(queryArgs, item.Val)
		writeSize += len(item.Val)

		if numItems >= maxBatchSize {
			if b.rdb.sqlPreparedStmt == nil {
				concatenatedPlaceholders := strings.Join(placeholders, ",")
				query := fmt.Sprintf(sqliteBatchQuery, concatenatedPlaceholders)

				stmt, err := b.rdb.sqlDB.Prepare(query)
				if err != nil {
					logger.Error("Error while prepare query", "err", err)
				}
				b.rdb.sqlPreparedStmt = stmt
			}

			batchWriteStart := time.Now()
			_, err := b.rdb.sqlPreparedStmt.Exec(queryArgs...)
			if err != nil {
				logger.Error("Error while batch write", "err", err)
				return err
			}

			writeTime := time.Since(batchWriteStart)
			logger.Info("BatchWrite 750 items", "elapsed", writeTime, "numItems", numItems, "writeSize", writeSize)
			relationalDBBatchWriteMeter.Mark(int64(writeTime / 750.0))

			placeholders = []string{}
			queryArgs = []interface{}{}
			numItems = 0
			writeSize = 0
		}
	}

	if numItems == 0 {
		return nil
	}

	startRemaining := time.Now()
	defer func() {
		writeRemainingTime := time.Since(startRemaining)
		logger.Info("BatchWrite Remainings", "elapsed", writeRemainingTime, "numItems", numItems)
		relationalDBBatchWriteMeter.Mark(int64(int64(writeRemainingTime) / int64(numItems)))
	}()
	var query string
	switch b.db.Dialect().GetName() {
	case mysqlDialect:
		query = fmt.Sprintf(mysqlBatchQuery, strings.Join(placeholders, ","))
	case postgresDialect:
		fallthrough
	case sqliteDialect:
		query = fmt.Sprintf(sqliteBatchQuery, strings.Join(placeholders, ","))

	default:
		return fmt.Errorf("%w - given dialect: %s", notSupportedDialectErr, b.db.Dialect().GetName())
	}

	err := b.db.Exec(query, queryArgs...).Error
	if err != nil && strings.Contains(err.Error(), "ON CONFLICT DO UPDATE command cannot affect row a second time") {
		logger.Error("2222", "err", err)
		for _, item := range b.batchItems {
			logger.Warn("batchItem Put", "key", common.BytesToHash(item.Key).String())
			if err2 := b.rdb.Put(item.Key, item.Val); err2 != nil {
				//logger.Error("1111", "err", err)
				return err2
			}
		}
		return nil
	}
	return err
}

func (b *rdbBatch) genPlaceholdersAndArgs() (string, []interface{}) {
	// TODO Below can be replaced by simple 'Create` when upgrading to gorm v2
	var placeholders []string
	var queryArgs []interface{}

	for _, item := range b.batchItems {
		placeholders = append(placeholders, "(?,?)")

		queryArgs = append(queryArgs, item.Key)
		queryArgs = append(queryArgs, item.Val)
	}

	return strings.Join(placeholders, ","), queryArgs
}

func (b *rdbBatch) ValueSize() int {
	return b.size
}

func (b *rdbBatch) Reset() {
	b.size = 0
	b.batchItems = []*KeyValueModel{}
}
